{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4007062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import regex\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import geopandas as gp\n",
    "import geoplot as gplt\n",
    "import geoplot.crs as gcrs\n",
    "import contextily as ctx\n",
    "import numpy as np\n",
    "import shapely as shapely\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import transform\n",
    "import collections\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Union, Generator, Optional\n",
    "from pyproj import Transformer, CRS, Proj\n",
    "import glob\n",
    "import os\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import advertools as adv\n",
    "import warnings\n",
    "import emoji\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dada92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gp.read_file(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Data\\RawData_Cleaned_Final.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to geodf, import using WGS 84 since that's how it exported from pgadmin\n",
    "gdf = gp.GeoDataFrame(df,geometry =gp.points_from_xy(df.long,df.lat),crs =4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fcc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproejct to Mollweide for visualization purposes later\n",
    "gdf.to_crs(\"ESRI:54009\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f0c12",
   "metadata": {},
   "source": [
    "## Start of temporal exploratory analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first I'll create columns with aggregated data information to make the creation of temporal subsets more straightforward\n",
    "gdf['post_publish_date'] = pd.to_datetime(gdf['post_publish_date'])\n",
    "gdf['Month/Year'] = gdf['post_publish_date'].dt.to_period('M')  # add new column showing timestamps aggregated to monthly intervals\n",
    "gdf['Week/Month'] = gdf['post_publish_date'].dt.to_period('W')  # add new column showing timestamps aggregated to weekly intervals\n",
    "gdf['HalfMonth'] = gdf['post_publish_date'] + pd.offsets.SemiMonthEnd()  # add new column showing timestamps aggregated to biweekly intervals\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart showing posts per month\n",
    "# note - dataset contains no data for november\n",
    "sns.set(style = 'whitegrid', font_scale=1.5)\n",
    "x = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September','October', 'December']\n",
    "y = gdf['Month/Year'].value_counts().sort_index()\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "width = 0.75\n",
    "ax.bar(x, y, width)\n",
    "plt.title(\"Number of Posts per Month\", size =25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd93e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chart showing posts per month\n",
    "# note - no data for november\n",
    "sns.set(style = 'whitegrid', font_scale=2)\n",
    "fig,ax =plt.subplots(figsize = (25,5))\n",
    "gdf['Week/Month'].value_counts().sort_index().plot(kind = 'bar')\n",
    "plt.title(\"Number of Tweets per Week\", size =35)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce530922",
   "metadata": {},
   "source": [
    "### Note: Significant gaps in data for April, October, and November are due to technical errors during prior data collection and cannot be avoided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b122a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now let's create sub-datasets for each month (these will also be the temporal subsets for the typicality calculations)\n",
    "gdf_jan = gdf[gdf['Month/Year'] == '2020-01']\n",
    "gdf_feb = gdf[gdf['Month/Year'] == '2020-02']\n",
    "gdf_mar = gdf[gdf['Month/Year'] == '2020-03']\n",
    "gdf_apr = gdf[gdf['Month/Year'] == '2020-04']\n",
    "gdf_may = gdf[gdf['Month/Year'] == '2020-05']\n",
    "gdf_jun = gdf[gdf['Month/Year'] == '2020-06']\n",
    "gdf_jul = gdf[gdf['Month/Year'] == '2020-07']\n",
    "gdf_aug = gdf[gdf['Month/Year'] == '2020-08']\n",
    "gdf_sep = gdf[gdf['Month/Year'] == '2020-09']\n",
    "gdf_oct = gdf[gdf['Month/Year'] == '2020-10']\n",
    "# reminder - no data for november\n",
    "gdf_dec = gdf[gdf['Month/Year'] == '2020-12']\n",
    "gdf_jan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89491ed",
   "metadata": {},
   "source": [
    "### Now i'll pinpoint more precise time frames with no data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid')\n",
    "fig,ax =plt.subplots(figsize = (10,5))\n",
    "gdf_apr['Week/Month'].value_counts().plot(kind = 'bar', width = 0.5)\n",
    "plt.title(\"Number of Tweets per Week\", size = 20)\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132c3ea1",
   "metadata": {},
   "source": [
    "### Note: no data for 2nd, 3rd, 4th week of April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid')\n",
    "fig,ax =plt.subplots(figsize = (15,5))\n",
    "gdf_oct['Week/Month'].value_counts().plot(kind = 'bar')\n",
    "plt.title(\"Number of Tweets per Week\", size = 20)\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d76e6",
   "metadata": {},
   "source": [
    "### Note: No data for 3rd, 4th week of october"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at changing popular emojis over time\n",
    "top_emojis_jan = most_common_emojis(gdf_jan['emoji'], 10)\n",
    "top_emojis_feb = most_common_emojis(gdf_feb['emoji'], 10)\n",
    "top_emojis_mar = most_common_emojis(gdf_mar['emoji'], 10)\n",
    "top_emojis_apr = most_common_emojis(gdf_apr['emoji'], 10)\n",
    "top_emojis_may = most_common_emojis(gdf_may['emoji'], 10)\n",
    "top_emojis_jun = most_common_emojis(gdf_jun['emoji'], 10)\n",
    "top_emojis_jul = most_common_emojis(gdf_jul['emoji'], 10)\n",
    "top_emojis_aug = most_common_emojis(gdf_aug['emoji'], 10)\n",
    "top_emojis_sep = most_common_emojis(gdf_sep['emoji'], 10)\n",
    "top_emojis_oct = most_common_emojis(gdf_oct['emoji'], 10)\n",
    "top_emojis_dec = most_common_emojis(gdf_dec['emoji'], 10)\n",
    "\n",
    "Months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"December\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f63da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: this part will not be performed with HLL data due to lack of temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_list = top_emojis_jan.Emoji.values.tolist()\n",
    "feb_list = top_emojis_feb.Emoji.values.tolist()\n",
    "mar_list = top_emojis_mar.Emoji.values.tolist()\n",
    "apr_list = top_emojis_apr.Emoji.values.tolist()\n",
    "may_list = top_emojis_may.Emoji.values.tolist()\n",
    "jun_list = top_emojis_jun.Emoji.values.tolist()\n",
    "jul_list = top_emojis_jul.Emoji.values.tolist()\n",
    "aug_list = top_emojis_aug.Emoji.values.tolist()\n",
    "sep_list = top_emojis_sep.Emoji.values.tolist()\n",
    "oct_list = top_emojis_oct.Emoji.values.tolist()\n",
    "dec_list = top_emojis_dec.Emoji.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1044b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_emojis_over_time = pd.DataFrame(columns = Months)\n",
    "top_emojis_over_time['January'] = jan_list\n",
    "top_emojis_over_time['February'] = feb_list\n",
    "top_emojis_over_time['March'] = mar_list\n",
    "top_emojis_over_time['April'] = apr_list\n",
    "top_emojis_over_time['May'] = may_list\n",
    "top_emojis_over_time['June'] = jun_list\n",
    "top_emojis_over_time['July'] = jul_list\n",
    "top_emojis_over_time['August'] = aug_list\n",
    "top_emojis_over_time['September'] = sep_list\n",
    "top_emojis_over_time['October'] = oct_list\n",
    "top_emojis_over_time['December'] = dec_list\n",
    "\n",
    "top_emojis_over_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d13ee61",
   "metadata": {},
   "source": [
    "## Now I'll generate some visualizations to get an overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49315a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create wordcloud of all hashtags in the dataset\n",
    "def make_wordcloud(newlist):\n",
    "    \n",
    "    hashtags = []\n",
    "    for item in newlist:\n",
    "        hashtags.append(item.lower().split(','))\n",
    "    flat_list = [item for sublist in hashtags for item in sublist]\n",
    "    \n",
    "    text = \" \".join(word for word in flat_list)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wordcloud =WordCloud(stopwords=stopwords,\n",
    "                         prefer_horizontal = 1,\n",
    "                         colormap = \"winter\",\n",
    "                         background_color=\"white\",\n",
    "                         width=1600, \n",
    "                         height=800,\n",
    "                         collocations = False,\n",
    "                         normalize_plurals=False).generate(text)    \n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "make_wordcloud(gdf['hashtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43187f",
   "metadata": {},
   "source": [
    "## let's take a closer look at some of the most popular hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to count the total frequency of the most commonly used hashtags\n",
    "def most_common_hashtags(labels, quantity):\n",
    "    #words = [i.split(\" \", 3)[0] for i in labels]\n",
    "    #counter = Counter(words).most_common(quantity)\n",
    "    hashtags = [(re.split(',', i)) for i in labels]\n",
    "    counter = Counter(x for xs in hashtags for x in set(xs)).most_common(quantity)\n",
    "    df = pd.DataFrame(counter, columns=[\"Hashtag\", \"Occurence number\"])\\\n",
    "                        .sort_values(by=\"Occurence number\", ascending=True)\n",
    "    \n",
    "    df = df[df[\"Hashtag\"] != \" \"].reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395e5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_hashtags = most_common_hashtags(gdf['hashtags'], 50)\n",
    "print(top_hashtags.sort_values(['Occurence number'], ascending=[False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284c99f",
   "metadata": {},
   "source": [
    "# explanations of some popular hashtags:\n",
    "p2000 = primarily from dutch safety alert system (bot)\n",
    "rrm = rotterdam rijnmond\n",
    "wetter = weather = primarily from german weather alert system (bot)\n",
    "canyaman = famous Turkish actor\n",
    "loveisland = famous british reality show\n",
    "nehody = 'accident' in czec and slovak (bot)\n",
    "günaydın = 'good morning' in turkish\n",
    "bts = famous kpop group \n",
    "gfvip = Grande Fratello VIP (Italian relaity show)\n",
    "yomequedoencasa = 'i stay at home' in spanish\n",
    "mon = several possibilities, one is the Mon district of Nagaland, India \n",
    "ken = abbreviation for city in the netherlands (bot)\n",
    "lfc = liverpool football club\n",
    "mufc = manchester united football club\n",
    "picemiyeti = \"Pi Society\" in Turkish - the name of a popular radio show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a separate function to create an emoji-cloud\n",
    "import emojis\n",
    "\n",
    "def make_emojilist(newlist):\n",
    "    \n",
    "    hashtags = []\n",
    "    for item in newlist:\n",
    "        hashtags.append(item.lower().split(','))\n",
    "    flat_list = [item for sublist in hashtags for item in sublist]\n",
    "    \n",
    "    text = \" \".join(str(word) for word in flat_list)\n",
    "    return text\n",
    "\n",
    "class EmojiCloud:\n",
    "    def __init__(self, font_path='./TwitterColorEmoji-SVGinOT.ttf'):\n",
    "        self.font_path = font_path\n",
    "        self.word_cloud = self.initialize_wordcloud()\n",
    "        self.emoji_probability = None\n",
    "\n",
    "        \n",
    "    def initialize_wordcloud(self):\n",
    "        return WordCloud(font_path=self.font_path,\n",
    "                               width=2000,\n",
    "                               height=1000,\n",
    "                               background_color='white',\n",
    "                               random_state=42,\n",
    "                               collocations=False)\n",
    "\n",
    "    \n",
    "    def color_func(self, word, font_size, position, orientation, random_state=None,\n",
    "                   **kwargs):\n",
    "        hue_saturation = '200, 88%'\n",
    "\n",
    "        current_emoji_probability = self.emoji_probability[word]\n",
    "        if current_emoji_probability >= 0.10:\n",
    "            opacity = 50\n",
    "        else:\n",
    "            opacity = 75 - current_emoji_probability/0.2 * 5\n",
    "        return f\"hsl({hue_saturation},{opacity}%)\"\n",
    "\n",
    "    def generate(self, text):\n",
    "        emoji_frequencies = Counter(emojis.iter(text))\n",
    "        total_count = sum(emoji_frequencies.values())\n",
    "        \n",
    "        self.emoji_probability = {emoji: count/total_count for emoji, count in emoji_frequencies.items()}\n",
    "        wc = self.word_cloud.generate_from_frequencies(emoji_frequencies)\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.imshow(wc.recolor(color_func=self.color_func, random_state=42))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eecf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojitext = make_emojilist(df['emoji'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3befd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_cloud = EmojiCloud(font_path='./TwitterColorEmoji-SVGinOT.ttf')\n",
    "emoji_cloud.generate(emojitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79000a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a bit hard to differentiate the emojis when they're all the same color - let's tweak it so each emoji is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b72800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a separate function to create an emoji-cloud with original colors\n",
    "class EmojiCloudNoColor:\n",
    "    def __init__(self, font_path='TwitterColorEmoji-SVGinOT.ttf'):\n",
    "        self.font_path = font_path\n",
    "        self.word_cloud = self.initialize_wordcloud_nocolor()\n",
    "        self.emoji_probability = None\n",
    "\n",
    "        \n",
    "    def initialize_wordcloud_nocolor(self):\n",
    "        return WordCloud(font_path=self.font_path,\n",
    "                               width=2000,\n",
    "                               height=1000,\n",
    "                               background_color='white',\n",
    "                               random_state=42,\n",
    "                               collocations=False)\n",
    "\n",
    "\n",
    "    def generate_nocolor(self, text):\n",
    "        emoji_frequencies = Counter(emojis.iter(text))\n",
    "        total_count = sum(emoji_frequencies.values())\n",
    "        \n",
    "        self.emoji_probability = {emoji: count/total_count for emoji, count in emoji_frequencies.items()}\n",
    "        wc = self.word_cloud.generate_from_frequencies(emoji_frequencies)\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.imshow(wc.recolor(color_func=None))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e46f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_cloud = EmojiCloudNoColor(font_path='./TwitterColorEmoji-SVGinOT.ttf')\n",
    "emoji_cloud.generate_nocolor(emojitext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb0fc6",
   "metadata": {},
   "source": [
    "### this is way too crowded - let's try again with only most common emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to count the total frequency of the most commonly used emojis\n",
    "def most_common_emojis(labels, quantity):\n",
    "    \"\"\"\n",
    "    Split all emoji groupings and count how many times each emoji is repeated in the list \n",
    "    labels (list) = List of strings to split.\n",
    "    quantity (int) = Number of most common emojis to return.\n",
    "    \"\"\"\n",
    "    #words = [i.split(\" \", 3)[0] for i in labels]\n",
    "    #counter = Counter(words).most_common(quantity)\n",
    "    emojis = [(re.split(',', i)) for i in labels]\n",
    "    counter = Counter(x for xs in emojis for x in set(xs)).most_common(quantity)\n",
    "    df = pd.DataFrame(counter, columns=[\"Emoji\", \"Occurence number\"])\\\n",
    "                        .sort_values(by=\"Occurence number\", ascending=False)\n",
    "    \n",
    "    df = df[df[\"Emoji\"] != \" \"].reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83433d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate absolute frequency for emojis as they appear in posts\n",
    "top_emojis = most_common_emojis(gdf['emoji'], 50)\n",
    "print(top_emojis.sort_values(['Occurence number'], ascending=[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13de7aec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's try it again with emojis with skin tone removed - see if it made a big difference\n",
    "top_emojis = most_common_emojis(gdf['emoji generic'], 50)\n",
    "print(top_emojis.sort_values(['Occurence number'], ascending=[False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622fcf7d",
   "metadata": {},
   "source": [
    "### looks like removing the skin tone causes a lot more skin-based emojis to be ranked higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9094d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_cloud = EmojiCloudNoColor(font_path='./TwitterColorEmoji-SVGinOT.ttf')\n",
    "emoji_cloud.generate_nocolor(top50emojitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b9b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis['Emoji']:\n",
    "    if rownum <= 49:\n",
    "        top_emojis.loc[rownum, 'Emoji Description'] = emoji.demojize(top_emojis.loc[rownum]['Emoji'])\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "print(top_emojis.sort_values(['Occurence number'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5013cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of emojis in the whole gdf\n",
    "def AllEmojiTotalCounter(totaldataset):\n",
    "    emojicounter = 0\n",
    "    for post in totaldataset['emoji generic']:\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n",
    "                emojicounter += 1\n",
    "    # print(\"Number of emojis in total dataset: \" + str(emojicounter))\n",
    "    return emojicounter\n",
    "\n",
    "AllEmojiTotalCounter(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce75d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate relative frequencies for each emoji \n",
    "top_emojis['Rel Freq'] = (top_emojis['Occurence number']/6923376) # 6923376 = number of emojis in dataset\n",
    "top_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229a711",
   "metadata": {},
   "source": [
    "### that information tells us a little bit about which emojis are used most often, but maybe the typicality measure can extract more meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set up functions to calculate each component of the typicality equation\n",
    "\n",
    "# number of a certain emoji within subset\n",
    "def EmojiSubsetCounter(emojiname, subset):\n",
    "    emojicounter = 0\n",
    "    for post in subset['emoji generic']:\n",
    "        if emojiname in post:\n",
    "            emojicounter += 1\n",
    "    # print(\"Number of \" + emojiname + \"in subset: \" + str(emojicounter))\n",
    "    return emojicounter\n",
    "\n",
    "\n",
    "# number of total emojis in subset\n",
    "def AllEmojiSubsetCounter(subset):\n",
    "    emojicounter = 0\n",
    "    for post in subset['emoji generic']:\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n",
    "                emojicounter += 1\n",
    "    # print(\"Number of emojis in subset: \" + str(emojicounter))\n",
    "    return emojicounter\n",
    "\n",
    "\n",
    "# number of specific emoji in whole dataset\n",
    "def EmojiTotalCounter(emojiname, totaldataset):\n",
    "    emojicounter = 0\n",
    "    for post in totaldataset['emoji generic']:\n",
    "        if emojiname in post:\n",
    "            emojicounter += 1\n",
    "    # print(\"Number of \" + emojiname + \"in total dataset: \" + str(emojicounter))\n",
    "    return emojicounter\n",
    "\n",
    "\n",
    "\n",
    "# number of emojis in whole dataset\n",
    "def AllEmojiTotalCounter(totaldataset):\n",
    "    emojicounter = 0\n",
    "    for post in totaldataset['emoji generic']:\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.UNICODE_EMOJI['en'] for char in word):\n",
    "                emojicounter += 1\n",
    "    # print(\"Number of emojis in total dataset: \" + str(emojicounter))\n",
    "    return emojicounter\n",
    "\n",
    "\n",
    "# typicality equation\n",
    "\n",
    "def TypicalityEquation (emojisubset, allemojisubset, emojitotal, allemojitotal):\n",
    "    t = ((emojisubset/allemojisubset)-(emojitotal/allemojitotal))/(emojitotal/allemojitotal)\n",
    "    # print(\"Typicality: \" + str(t))\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f3e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each of the top 50 emojis, calculate the typicality per month\n",
    "rownum = 0\n",
    "for row in top_emojis['Emoji']:\n",
    "    if rownum <= 49:\n",
    "        emo = top_emojis.loc[rownum]['Emoji']\n",
    "        emocount_total = top_emojis.loc[rownum]['Occurence number']\n",
    "        top_emojis.loc[rownum, 'T_Jan'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jan), AllEmojiSubsetCounter(gdf_jan), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Feb'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_feb), AllEmojiSubsetCounter(gdf_feb), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Mar'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_mar), AllEmojiSubsetCounter(gdf_mar), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Apr'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_apr), AllEmojiSubsetCounter(gdf_apr), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_May'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_may), AllEmojiSubsetCounter(gdf_may), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Jun'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jun), AllEmojiSubsetCounter(gdf_jun), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Jul'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jul), AllEmojiSubsetCounter(gdf_jul), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Aug'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_aug), AllEmojiSubsetCounter(gdf_aug), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Sep'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_sep), AllEmojiSubsetCounter(gdf_sep), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Oct'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_oct), AllEmojiSubsetCounter(gdf_oct), emocount_total, 6923376)\n",
    "        top_emojis.loc[rownum, 'T_Dec'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_dec), AllEmojiSubsetCounter(gdf_dec), emocount_total, 6923376)\n",
    "        print(\"done\" + str(rownum))\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "print(top_emojis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928557ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename columns (to make future plots look nicer)\n",
    "\n",
    "top_emojis = top_emojis.rename(columns={\"T_Jan\": \"Jan\", \"T_Feb\": \"Feb\", \"T_Mar\": \"Mar\", \"T_Apr\": \"Apr\", \"T_May\": \"May\", \n",
    "                           \"T_Jun\": \"Jun\", \"T_Jul\": \"Jul\", \"T_Aug\": \"Aug\", \"T_Sep\": \"Sep\", \"T_Oct\": \"Oct\", \"T_Dec\": \"Dec\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for plotting\n",
    "columns_trans = top_emojis.transpose()\n",
    "columns_trans.columns = columns_trans.iloc[0]\n",
    "columns_trans = columns_trans.transpose()\n",
    "columns_trans = columns_trans.drop(columns=['Emoji', 'Occurence number'])\n",
    "columns_trans = columns_trans.transpose()\n",
    "columns_trans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a10172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's an example for just one emoji\n",
    "columns_trans['❤️'].plot(ylim=(-1,1), title=\"Temporal Typicality of \" + emoji.demojize('❤️').replace(\":\",\"\").replace(\"_\", \" \").title() + \" Emoji\", linewidth=5,grid=True, ylabel=\"Typicality\", xlabel=\"Month\", fontsize = 12)\n",
    "# columns_trans['😂'].plot(ylim=(-1,1), title='Temporal Typicality of Face With Tears Of Joy Emoji', linewidth=5,grid=True, ylabel=\"Typicality\", xlabel=\"Month\", fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430585e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titlelist = []\n",
    "for col in columns_trans.columns:\n",
    "    addon = emoji.demojize(col).replace(\":\",\"\")\n",
    "    addon = addon.replace(\"_\", \" \")\n",
    "    addon = addon.title()\n",
    "    titlelist.append(addon)\n",
    "titlelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddede80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_trans.plot(ylim=(-1,1),figsize=(100, 150), subplots=True,layout=(10, 5), title=titlelist, grid=True, ylabel=\"Typicality\", xlabel=\"Month\", linewidth = 5, sharex=False, legend=False, fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b431bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_trans.plot(ylim=(-1,1),figsize=(100, 150), subplots=True,layout=(10, 5), title=None, grid=True, \n",
    "                         linewidth = 10, sharex=True, sharey=True, legend=False, fontsize = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5718637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also perform this calculation on the top 50 emojis by userdays (to avoid bias from overactive users)\n",
    "top_emojis_ud = {'😂': 190683,\n",
    "     '❤️': 187938,\n",
    "     '😍': 130963,\n",
    "     '👏': 99485,\n",
    "     '👍': 95117,\n",
    "     '🙏': 93921,\n",
    "     '💪': 87392,\n",
    "     '🤣': 82473,\n",
    "     '💙': 82002,\n",
    "     '😊': 69271,\n",
    "     '🔥': 66638,\n",
    "     '😉': 65919,\n",
    "     '🥰': 59354,\n",
    "     '😎': 58073,\n",
    "     '😁': 54824,\n",
    "     '🤔': 52586,\n",
    "     '👌': 50397,\n",
    "     '🙌': 45654,\n",
    "     '💛': 45365,\n",
    "     '☀️': 44965,\n",
    "     '💚': 41228,\n",
    "     '⚽️': 40216,\n",
    "     '😭': 39637,\n",
    "     '✨': 38818,\n",
    "     '💜': 37766,\n",
    "     '🖤': 37687,\n",
    "     '😘': 37036,\n",
    "     '👇': 36136,\n",
    "     '😅': 35820,\n",
    "     '🤩': 35565,\n",
    "     '🔴': 34552,\n",
    "     '♥️': 33384,\n",
    "     '📸': 33003,\n",
    "     '🙄': 31538,\n",
    "     '💕': 31422,\n",
    "     '🤗': 30618,\n",
    "     '🎉': 29751,\n",
    "     '🎶': 29636,\n",
    "     '😋': 27232,\n",
    "     '👀': 27175,\n",
    "     '😀': 27025,\n",
    "     '🌈': 26916,\n",
    "     '👉': 26892,\n",
    "     '🙈': 24852,\n",
    "     '🥳': 24477,\n",
    "     '😜': 24255,\n",
    "     '✅': 22893,\n",
    "     '😱': 22194,\n",
    "     '😷': 21079,\n",
    "     '🌞': 20908}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34073c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_emojis_ud_df = pd.DataFrame(list(top_emojis_ud.items()), columns=['Emoji', 'Userdays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't use most_common_emojis function since it won't take a list of emojis as an input - se I'll design another counter\n",
    "rownum = 0\n",
    "for row in top_emojis_ud_df['Emoji']:\n",
    "    if rownum <= 49:\n",
    "        emo = top_emojis_ud_df.loc[rownum]['Emoji']\n",
    "        emocount = 0\n",
    "        for row in gdf['emoji generic']:\n",
    "            if emo in row:\n",
    "                emocount = emocount +1\n",
    "        top_emojis_ud_df.loc[rownum, 'Occurrence number'] = emocount\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_ud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227fe73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add column of emoji description, relative frequency, typicality per month\n",
    "rownum = 0\n",
    "for row in top_emojis_ud_df['Emoji']:\n",
    "    if rownum <= 49:\n",
    "        top_emojis_ud_df.loc[rownum, 'Emoji Description'] = emoji.demojize(top_emojis_ud_df.loc[rownum]['Emoji'])\n",
    "        top_emojis_ud_df['Rel Freq'] = (top_emojis_ud_df['Occurrence number']/6923376) # 6923376 = number of emojis in dataset\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "top_emojis_ud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "### it's unlear why the soccer ball emoji is 0, but this function will allow for it\n",
    "rownum = 0\n",
    "for row in top_emojis_ud_df['Emoji']:\n",
    "    if rownum <= 49:\n",
    "        emo = top_emojis_ud_df.loc[rownum]['Emoji']\n",
    "        emocount_total = top_emojis_ud_df.loc[rownum]['Occurrence number']\n",
    "        if top_emojis_ud_df.loc[rownum, 'Occurrence number'] == 0:  \n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jan'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Feb'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Mar'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Apr'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_May'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jun'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jul'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Aug'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Sep'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Oct'] = 0\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Dec'] = 0\n",
    "#             print(\"done\" + str(rownum))\n",
    "            rownum = rownum + 1\n",
    "        else:\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jan'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jan), AllEmojiSubsetCounter(gdf_jan), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Feb'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_feb), AllEmojiSubsetCounter(gdf_feb), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Mar'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_mar), AllEmojiSubsetCounter(gdf_mar), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Apr'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_apr), AllEmojiSubsetCounter(gdf_apr), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_May'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_may), AllEmojiSubsetCounter(gdf_may), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jun'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jun), AllEmojiSubsetCounter(gdf_jun), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Jul'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jul), AllEmojiSubsetCounter(gdf_jul), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Aug'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_aug), AllEmojiSubsetCounter(gdf_aug), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Sep'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_sep), AllEmojiSubsetCounter(gdf_sep), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Oct'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_oct), AllEmojiSubsetCounter(gdf_oct), emocount_total, 6923376)\n",
    "            top_emojis_ud_df.loc[rownum, 'T_Dec'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_dec), AllEmojiSubsetCounter(gdf_dec), emocount_total, 6923376)\n",
    "#             print(\"done\" + str(rownum))\n",
    "            rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "# top_emojis_ud_df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df to csv \n",
    "top_emojis_ud_df.to_csv(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Data\\TopEmojisHLL_MonthlyTypicality.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4565fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back in (optional, to avoid re-running above code in the future)\n",
    "top_emojis_ud_df = pd.read_csv(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Data\\TopEmojisHLL_MonthlyTypicality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_emojis_ud_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48473c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename columns (to make future plots look nicer)\n",
    "\n",
    "top_emojis_ud_df = top_emojis_ud_df.rename(columns={\"T_Jan\": \"Jan\", \"T_Feb\": \"Feb\", \"T_Mar\": \"Mar\", \"T_Apr\": \"Apr\", \"T_May\": \"May\", \n",
    "                           \"T_Jun\": \"Jun\", \"T_Jul\": \"Jul\", \"T_Aug\": \"Aug\", \"T_Sep\": \"Sep\", \"T_Oct\": \"Oct\", \"T_Dec\": \"Dec\"})\n",
    "\n",
    "# prepare data for plotting\n",
    "columns_trans_ud = top_emojis_ud_df.transpose()\n",
    "columns_trans_ud.columns = columns_trans_ud.iloc[0]\n",
    "columns_trans_ud = columns_trans_ud.transpose()\n",
    "columns_trans_ud = columns_trans_ud.drop(columns=['Emoji', 'Unnamed: 0', 'Rel Freq', 'Occurrence number', 'Emoji Description', 'Userdays'])\n",
    "columns_trans_ud = columns_trans_ud.transpose()\n",
    "\n",
    "# # make new list of titles\n",
    "# titlelist2 = []\n",
    "# for col in columns_trans_ud.columns:\n",
    "#     addon = emoji.demojize(col).replace(\":\",\"\")\n",
    "#     addon = addon.replace(\"_\", \" \")\n",
    "#     addon = addon.title()\n",
    "#     titlelist2.append(addon)\n",
    "\n",
    "# plot\n",
    "columns_trans_ud.plot(ylim=(-1,1),figsize=(100, 150), subplots=True,layout=(10, 5), title=None, grid=True, \n",
    "                      linewidth = 10, sharex=True, sharey=True, legend=False, fontsize = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0186f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked face emoji goes off the chart, let's look at it alone\n",
    "\n",
    "columns_trans_ud[48].plot(ylim=(-1,1.5), title=\"Temporal Typicality of \" + emoji.demojize('😷').replace(\":\",\"\").replace(\"_\", \" \").title() + \" Emoji\", linewidth=5, fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34d4a2",
   "metadata": {},
   "source": [
    "# begin spatial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a36647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spatial subsets, starting with country boundaries\n",
    "countries_gdf = gp.read_file(\"Europe_Clipped_BBox.shp\")\n",
    "countries_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_gdf.to_crs(\"ESRI:54009\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20893005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the custom shapefile (clipped to fit data)\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "countries_gdf.plot(ax=ax)\n",
    "ax.set_title(\"Study Area\", fontsize=20)\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c1224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the points on top of study area - this takes quite a while\n",
    "fig, ax = plt.subplots(figsize=(35, 20))\n",
    "countries_gdf.boundary.plot(ax=ax, color=\"black\")\n",
    "gdf.plot(ax=ax, color=\"purple\", markersize=3, alpha = 0.5)\n",
    "ax.set_title(\"Twitter Post Locations\", fontsize=20)\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "fig.savefig(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Figures\\AllPosts_mapped.png\", dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_ud = {'United Kingdom': 810535,\n",
    " 'France': 230294,\n",
    " 'Spain': 288819,\n",
    " 'Italy': 141807,\n",
    " 'Germany': 142974,\n",
    " 'Netherlands': 73083,\n",
    " 'Turkey': 108351,\n",
    " 'Czech Republic': 10711,\n",
    " 'Belgium': 39852,\n",
    " 'Switzerland': 23061,\n",
    " 'Portugal': 12699,\n",
    " 'Austria': 18070}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ec1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from HLL data, I know that the top 10 countries by userdays are:\n",
    "#  ('United Kingdom', 810535),\n",
    "#  ('Spain', 288819),\n",
    "#  ('France', 230294),\n",
    "#  ('Germany', 142974),\n",
    "#  ('Italy', 141807),\n",
    "#  ('Turkey', 108351),\n",
    "#  ('Netherlands', 73083),\n",
    "#  ('Belgium', 39852),\n",
    "#  ('Switzerland', 23061),\n",
    "#  ('Austria', 18070),\n",
    "\n",
    "#extracting boundaries of countries for making specific country based grids \n",
    "\n",
    "uk = countries_gdf[countries_gdf['NAME_EN'] == \"United Kingdom\"]\n",
    "sp = countries_gdf[countries_gdf['NAME_EN'] == \"Spain\"]\n",
    "fr = countries_gdf[countries_gdf['NAME_EN'] == \"France\"]\n",
    "de = countries_gdf[countries_gdf['NAME_EN'] == \"Germany\"]\n",
    "it = countries_gdf[countries_gdf['NAME_EN'] == \"Italy\"]\n",
    "tu = countries_gdf[countries_gdf['NAME_EN'] == \"Turkey\"]\n",
    "ne = countries_gdf[countries_gdf['NAME_EN'] == \"Netherlands\"]\n",
    "be = countries_gdf[countries_gdf['NAME_EN'] == \"Belgium\"]\n",
    "sw = countries_gdf[countries_gdf['NAME_EN'] == \"Switzerland\"]\n",
    "au = countries_gdf[countries_gdf['NAME_EN'] == \"Austria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot countries\n",
    "fig, (ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10) = plt.subplots(1,10,figsize = (15,10))\n",
    "\n",
    "for ax in (ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10):\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "ax1.title.set_text('UK')\n",
    "ax2.title.set_text('SP')\n",
    "ax3.title.set_text('FR')\n",
    "ax4.title.set_text('GE')\n",
    "ax5.title.set_text('IT')\n",
    "ax6.title.set_text('TU')\n",
    "ax7.title.set_text('NE')\n",
    "ax8.title.set_text('BE')\n",
    "ax9.title.set_text('SW')\n",
    "ax10.title.set_text('AU')\n",
    "\n",
    "\n",
    "uk.plot(ax=ax1)\n",
    "sp.plot(ax=ax2)\n",
    "fr.plot(ax=ax3)\n",
    "de.plot(ax=ax4)\n",
    "it.plot(ax=ax5)\n",
    "tu.plot(ax=ax6)\n",
    "ne.plot(ax=ax7)\n",
    "be.plot(ax=ax8)\n",
    "sw.plot(ax=ax9)\n",
    "au.plot(ax=ax10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76aaeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct spatial joins so that the gdf is split up by country - this takes a looooong time\n",
    "\n",
    "uk_join = gdf.sjoin(uk, how=\"right\")\n",
    "sp_join = gdf.sjoin(sp, how=\"right\")\n",
    "fr_join = gdf.sjoin(fr, how=\"right\")\n",
    "ge_join = gdf.sjoin(de, how=\"right\")\n",
    "it_join = gdf.sjoin(it, how=\"right\")\n",
    "tu_join = gdf.sjoin(tu, how=\"right\")\n",
    "ne_join = gdf.sjoin(ne, how=\"right\")\n",
    "be_join = gdf.sjoin(be, how=\"right\")\n",
    "sw_join = gdf.sjoin(sw, how=\"right\")\n",
    "au_join = gdf.sjoin(au, how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c385b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin individual spatial analysis by country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f690367",
   "metadata": {},
   "source": [
    "# United Kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc5d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_uk = most_common_emojis(uk_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_uk['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_uk.loc[rownum, 'Emoji']\n",
    "        top_emojis_uk.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_uk.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, uk_join), AllEmojiSubsetCounter(uk_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_uk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf341e4",
   "metadata": {},
   "source": [
    "# Spain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis for each country\n",
    "top_emojis_sp = most_common_emojis(sp_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_sp['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_sp.loc[rownum, 'Emoji']\n",
    "        top_emojis_sp.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_sp.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, sp_join), AllEmojiSubsetCounter(sp_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a756c7",
   "metadata": {},
   "source": [
    "# France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8595f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_fr = most_common_emojis(fr_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_fr['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_fr.loc[rownum, 'Emoji']\n",
    "        top_emojis_fr.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_fr.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, fr_join), AllEmojiSubsetCounter(fr_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e6f26",
   "metadata": {},
   "source": [
    "# Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8de50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis for each country\n",
    "top_emojis_ge = most_common_emojis(ge_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_ge['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_ge.loc[rownum, 'Emoji']\n",
    "        top_emojis_ge.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_ge.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, ge_join), AllEmojiSubsetCounter(ge_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_ge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85942a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the umbrella emoji seems to be extremely typical for Germany - let's dig a little deeper and find out why that is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of times umbrella used in germany\n",
    "print(EmojiTotalCounter('☔', ge_join))\n",
    "#number of times used in europe\n",
    "print(EmojiTotalCounter('☔', gdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48957b",
   "metadata": {},
   "source": [
    "#### One possible explanation for the popularity of the umbrella emoji is it's significance with the Hong Kong pro-democracy protests and Black Lives Matter movements. Of course it could also just refer to weather. Let's find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at posts containing umbrellas in germany\n",
    "ge_umbrellaposts = ge_join[ge_join['emoji'].str.contains('☂')]\n",
    "ge_umbrellaposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to count the total frequency of the most commonly used emojis\n",
    "def most_common_hashtags(labels, quantity):\n",
    "    \"\"\"\n",
    "    labels (list) = List of strings to split.\n",
    "    quantity (int) = Number of most common hashtags to return.\n",
    "    \"\"\"\n",
    "    #words = [i.split(\" \", 3)[0] for i in labels]\n",
    "    #counter = Counter(words).most_common(quantity)\n",
    "    hashtags = [(re.split(',', i)) for i in labels]\n",
    "    counter = Counter(x for xs in hashtags for x in set(xs)).most_common(quantity)\n",
    "    umbrella_hashtags = pd.DataFrame(counter, columns=[\"Hashtag\", \"Occurence number\"])\\\n",
    "                        .sort_values(by=\"Occurence number\", ascending=False)\n",
    "    \n",
    "    umbrella_hashtags = umbrella_hashtags[umbrella_hashtags[\"Hashtag\"] != \" \"].reset_index(drop=True)\n",
    "    \n",
    "    return umbrella_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8941000",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "most_common_hashtags(ge_umbrellaposts['hashtags'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f4747",
   "metadata": {},
   "source": [
    "Ok, looks like the umbrella emoji is actually mostly weather related"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a45df6",
   "metadata": {},
   "source": [
    "# Italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5b9cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_it = most_common_emojis(it_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_it['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_it.loc[rownum, 'Emoji']\n",
    "        top_emojis_it.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_it.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, it_join), AllEmojiSubsetCounter(it_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7410b8",
   "metadata": {},
   "source": [
    "# Turkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f37c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_tu = most_common_emojis(tu_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_tu['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_tu.loc[rownum, 'Emoji']\n",
    "        top_emojis_tu.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_tu.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, tu_join), AllEmojiSubsetCounter(tu_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_tu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b211471",
   "metadata": {},
   "source": [
    "# Netherlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_ne = most_common_emojis(ne_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_ne['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_ne.loc[rownum, 'Emoji']\n",
    "        top_emojis_ne.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_ne.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, ne_join), AllEmojiSubsetCounter(ne_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_ne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad79ef",
   "metadata": {},
   "source": [
    "### shouldn't the red circle emoji have a high typicality, since it is used comparatively often in the netherlands compared to the total dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54b687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EmojiTotalCounter('🔴', ne_join))\n",
    "print(EmojiSubsetCounter('🔴', ne_join))\n",
    "print(AllEmojiSubsetCounter(ne_join))\n",
    "print(EmojiTotalCounter('🔴', gdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this phenomenon specific to netherlands? Let's calculate the typicality of the red circle emoji using the dutch subset\n",
    "ne_redcircle_typicality = TypicalityEquation(EmojiSubsetCounter('🔴', ne_join), AllEmojiSubsetCounter(ne_join), EmojiTotalCounter('🔴', gdf), 6923376)\n",
    "ne_redcircle_typicality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fdd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "redcircleposts = gdf[gdf['emoji'].str.contains('🔴')]\n",
    "most_common_hashtags(redcircleposts['hashtags'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2672b",
   "metadata": {},
   "source": [
    "#samensterk = together we are strong (covid-related)\n",
    "#denhaag - city\n",
    "#hgl - region haaglanden (around den haag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4843af",
   "metadata": {},
   "source": [
    "### let's look at the temporal trend of emojis containing the red circle emojis - do they correspond with covid restrictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949fa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style = 'whitegrid')\n",
    "fig,ax =plt.subplots(figsize = (20,5))\n",
    "ne_join['Week/Month'].value_counts().sort_index().plot(kind = 'bar')\n",
    "plt.title(\"Number of 🔴 Tweets per Week\", size =15)\n",
    "plt.xticks(rotation=0)\n",
    "plt.locator_params(nbins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b6b61",
   "metadata": {},
   "source": [
    "from these results, it doesn't seem that there's a significant spike in red circle emojis corresponding with the start of the pandemic (March 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e35c5bb",
   "metadata": {},
   "source": [
    "# Belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090fd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_be = most_common_emojis(be_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_be['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_be.loc[rownum, 'Emoji']\n",
    "        top_emojis_be.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_be.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, be_join), AllEmojiSubsetCounter(be_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379e3f1",
   "metadata": {},
   "source": [
    "# Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_sw = most_common_emojis(sw_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_sw['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_sw.loc[rownum, 'Emoji']\n",
    "        top_emojis_sw.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_sw.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, sw_join), AllEmojiSubsetCounter(sw_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_sw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725d381",
   "metadata": {},
   "source": [
    "# Austria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate top 10 emojis \n",
    "top_emojis_au = most_common_emojis(au_join['emoji generic'], 10)\n",
    "# add column of emoji description\n",
    "rownum = 0\n",
    "for row in top_emojis_au['Emoji']:\n",
    "    if rownum <= 9:\n",
    "        emo = top_emojis_au.loc[rownum, 'Emoji']\n",
    "        top_emojis_au.loc[rownum, 'Emoji Description'] = emoji.demojize(emo).replace(\":\",\"\")\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        top_emojis_au.loc[rownum, 'Typicality'] = TypicalityEquation(EmojiSubsetCounter(emo, au_join), AllEmojiSubsetCounter(au_join), emocount_total, 6923376)\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "top_emojis_au\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd930287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare top emojis across countries\n",
    "# United Kingdom\n",
    "# Spain\n",
    "# France\n",
    "# Germany\n",
    "# Italy\n",
    "# Turkey\n",
    "# Netherlands\n",
    "# Belgium\n",
    "# Switzerland\n",
    "# Austria\n",
    "\n",
    "\n",
    "uk_list = top_emojis_uk.Emoji.values.tolist()\n",
    "sp_list = top_emojis_sp.Emoji.values.tolist()\n",
    "fr_list = top_emojis_fr.Emoji.values.tolist()\n",
    "ge_list = top_emojis_ge.Emoji.values.tolist()\n",
    "it_list = top_emojis_it.Emoji.values.tolist()\n",
    "tu_list = top_emojis_tu.Emoji.values.tolist()\n",
    "ne_list = top_emojis_ne.Emoji.values.tolist()\n",
    "be_list = top_emojis_be.Emoji.values.tolist()\n",
    "sw_list = top_emojis_sw.Emoji.values.tolist()\n",
    "au_list = top_emojis_au.Emoji.values.tolist()\n",
    "\n",
    "top_emojis_by_country = pd.DataFrame(columns = ['United Kingdom', 'Spain', 'France', 'Germany','Italy', 'Turkey', 'Netherlands',\n",
    "                                                'Belgium', 'Switzerland', 'Austria'])\n",
    "top_emojis_by_country['United Kingdom'] = uk_list\n",
    "top_emojis_by_country['Spain'] = sp_list\n",
    "top_emojis_by_country['France'] = fr_list\n",
    "top_emojis_by_country['Germany'] = ge_list\n",
    "top_emojis_by_country['Italy'] = it_list\n",
    "top_emojis_by_country['Turkey'] = tu_list\n",
    "top_emojis_by_country['Netherlands'] = ne_list\n",
    "top_emojis_by_country['Belgium'] = be_list\n",
    "top_emojis_by_country['Switzerland'] = sw_list\n",
    "top_emojis_by_country['Austria'] = au_list\n",
    "\n",
    "d = dict(selector=\"th\",\n",
    "    props=[('text-align', 'center')])\n",
    "\n",
    "top_emojis_over_time.style.set_properties(**{'width':'6em', 'text-align':'center'})\\\n",
    "        .set_table_styles([d])\n",
    "\n",
    "top_emojis_by_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c80de3f",
   "metadata": {},
   "source": [
    "# re-calculate typicality for next 50 most frequently used emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try it with emojis with skin tone removed\n",
    "top_emojis_100 = most_common_emojis(gdf['emoji generic'], 100)\n",
    "print(top_emojis_100.sort_values(['Occurence number'], ascending=[False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll filter out the top 50, since those were already analyzed\n",
    "nexttop50 = top_emojis_100.iloc[50: , :]\n",
    "nexttop50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e904c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add column of emoji description\n",
    "rownum = 50\n",
    "for row in nexttop50['Emoji']:\n",
    "    if rownum <= 99:\n",
    "        nexttop50.loc[rownum, 'Emoji Description'] = emoji.demojize(nexttop50.loc[rownum]['Emoji'])\n",
    "        # calculate relative frequencies for each emoji \n",
    "        nexttop50['Rel Freq'] = (nexttop50['Occurence number']/6923376) # 6923376 = number of emojis in dataset\n",
    "        emo = nexttop50.loc[rownum]['Emoji']\n",
    "        emocount_total = nexttop50.loc[rownum]['Occurence number']\n",
    "        nexttop50.loc[rownum, 'T_Jan'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jan), AllEmojiSubsetCounter(gdf_jan), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Feb'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_feb), AllEmojiSubsetCounter(gdf_feb), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Mar'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_mar), AllEmojiSubsetCounter(gdf_mar), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Apr'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_apr), AllEmojiSubsetCounter(gdf_apr), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_May'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_may), AllEmojiSubsetCounter(gdf_may), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Jun'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jun), AllEmojiSubsetCounter(gdf_jun), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Jul'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_jul), AllEmojiSubsetCounter(gdf_jul), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Aug'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_aug), AllEmojiSubsetCounter(gdf_aug), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Sep'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_sep), AllEmojiSubsetCounter(gdf_sep), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Oct'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_oct), AllEmojiSubsetCounter(gdf_oct), emocount_total, 6923376)\n",
    "        nexttop50.loc[rownum, 'T_Dec'] = TypicalityEquation(EmojiSubsetCounter(emo, gdf_dec), AllEmojiSubsetCounter(gdf_dec), emocount_total, 6923376)\n",
    "\n",
    "        rownum = rownum + 1\n",
    "    else:\n",
    "        break\n",
    "print(nexttop50.sort_values(['Occurence number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da883f",
   "metadata": {},
   "source": [
    "# Instead of most frequently used, now let's look at the most TYPICAL emojis by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to count the total frequency of all emojis\n",
    "def count_all_emojis(labels):\n",
    "    \"\"\"\n",
    "    Split all emoji groupings and count how many times each emoji is repeated in the list \n",
    "    labels (list) = List of strings to split.\n",
    "    \"\"\"\n",
    "    emojis = [(re.split(',', i)) for i in labels]\n",
    "    \n",
    "    counter = Counter(x for xs in emojis for x in set(xs))\n",
    "    df = pd.DataFrame.from_dict(counter, orient='index', columns=[\"Occurrence number\"]).sort_values(by=\"Occurrence number\", ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9017e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test it out on the uk\n",
    "uk_emojis = count_all_emojis(uk_join['emoji generic'])\n",
    "uk_emojis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de616aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row in table, calculate typicality only if occurrence number > 1000\n",
    "uk_emojis_typ = uk_emojis[uk_emojis['Occurrence number'] >= 1000] # this is necessary because typicality values become skewed for infrequently used emojis\n",
    "index = uk_emojis_typ.index\n",
    "allemojisubset = AllEmojiSubsetCounter(uk_join)\n",
    "for emo in index:\n",
    "    uk_emojis_typ.loc[emo, 'Emoji description'] = emoji.demojize(emo)\n",
    "    emojisubset = uk_emojis_typ.loc[emo, 'Occurrence number']\n",
    "    emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "    uk_emojis_typ.loc[emo, 'Typicality'] = TypicalityEquation(emojisubset, allemojisubset, emocount_total, 6923376)\n",
    "uk_emojis_typ.sort_values(by=\"Typicality\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a66306",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_countries = {\n",
    "    \"United Kingdom\": uk_join,\n",
    "    \"Spain\": sp_join,\n",
    "    \"France\": fr_join,\n",
    "    \"Germany\": ge_join,\n",
    "    \"Italy\": it_join,\n",
    "    \"Turkey\": tu_join,\n",
    "    \"Netherlands\": ne_join,\n",
    "    \"Belgium\": be_join,\n",
    "    \"Switzerland\": sw_join,\n",
    "    \"Austria\": au_join\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat this process for top 10 countries by userday\n",
    "country_typ ={}\n",
    "for country, join in top_countries.items():\n",
    "    emojicount = count_all_emojis(join['emoji generic'])\n",
    "    co_emojis_typ = emojicount[emojicount['Occurrence number'] >= 1000] # this is necessary because typicality values become skewed for infrequently used emojis\n",
    "    index = co_emojis_typ.index\n",
    "    allemojisubset = AllEmojiSubsetCounter(join)\n",
    "    for emo in index:\n",
    "        co_emojis_typ.loc[emo, 'Emoji description'] = emoji.demojize(emo)\n",
    "#         emojisubset = co_emojis_typ.loc[emo, 'Occurrence number']\n",
    "        emosubset = EmojiSubsetCounter(emo, join)\n",
    "        emocount_total = EmojiTotalCounter(emo, gdf)\n",
    "        co_emojis_typ.loc[emo, 'Typicality'] = TypicalityEquation(emojisubset, allemojisubset, emocount_total, 6923376)\n",
    "    country_typ[country] = co_emojis_typ.sort_values(by=\"Typicality\", ascending=False)\n",
    "    \n",
    "country_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, df in country_typ.items():\n",
    "    # save df to csv \n",
    "    df.to_csv(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Data\\EmojiTypicality_\" + country + \".csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_countries_list = [\n",
    "    \"United Kingdom\",\n",
    "    \"Spain\",\n",
    "    \"France\",\n",
    "    \"Germany\",\n",
    "    \"Italy\",\n",
    "    \"Turkey\",\n",
    "    \"Netherlands\",\n",
    "    \"Belgium\",\n",
    "    \"Switzerland\",\n",
    "    \"Austria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data back in so I don't have to re-run the whole program in the future\n",
    "country_typ = {}\n",
    "for country in top_countries_list:\n",
    "    country_typ[country] = pd.read_csv(r\"C:\\Users\\saman\\OneDrive\\Documents\\Thesis\\Data\\TypicalEmojis_ByCountry\\EmojiTypicality_\" + country + \".csv\", index_col=False)\n",
    "country_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_country_typ = {}\n",
    "for country, df in country_typ.items():\n",
    "    pos_df = df.drop(df.index[df['Typicality'] < 0])\n",
    "    pos_country_typ[country] = pos_df\n",
    "    \n",
    "pos_country_typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most typical emojis per country will now be analyzed in the Emoji-Specific Analysis notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
